{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b40a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-24 21:50:33.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: D:\\workspace\\projects\\freelance\\BRepMocAutoencoder\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path: d:\\workspace\\projects\\freelance\\BRepMocAutoencoder\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import notebook_setup\n",
    "from src.config import INTERIM_DATA_DIR, PROCESSED_DATA_DIR, REPORTS_DIR, EXTERNAL_DATA_DIR, MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a26e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcde1eff",
   "metadata": {},
   "source": [
    "загрузка датасета и проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c5f19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 9, Val samples: 3, Test samples: 2\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Feature has zero standard deviation",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m test_dataset = BrepNetDataset(STATS_BREPNET, BREP_NPZ_DIR, split=\u001b[33m\"\u001b[39m\u001b[33mtest_set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Val samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Test samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.items():\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(v.shape)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28misinstance\u001b[39m(v,\u001b[38;5;250m \u001b[39mtorch.Tensor)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\workspace\\projects\\freelance\\BRepMocAutoencoder\\src\\dataset.py:69\u001b[39m, in \u001b[36mBrepNetDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Стандартизация только для обучающей выборки\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_standardization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     data = \u001b[43mstandarize_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_standardization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     72\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: file_name,\n\u001b[32m     73\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mvertices\u001b[39m\u001b[33m\"\u001b[39m: torch.from_numpy(data[\u001b[33m\"\u001b[39m\u001b[33mvertex\u001b[39m\u001b[33m\"\u001b[39m].astype(np.float32)),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msdf_vals\u001b[39m\u001b[33m\"\u001b[39m: vals.contiguous()      \u001b[38;5;66;03m# [n_faces, n_samples]\u001b[39;00m\n\u001b[32m     81\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\workspace\\projects\\freelance\\BRepMocAutoencoder\\src\\dataset.py:20\u001b[39m, in \u001b[36mstandarize_data\u001b[39m\u001b[34m(data, feature_standardization)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstandarize_data\u001b[39m(data, feature_standardization):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33mface_features\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mstandardize_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mface_features\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_standardization\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mface_features\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33medge_features\u001b[39m\u001b[33m\"\u001b[39m] = standardize_features(data[\u001b[33m\"\u001b[39m\u001b[33medge_features\u001b[39m\u001b[33m\"\u001b[39m], feature_standardization[\u001b[33m\"\u001b[39m\u001b[33medge_features\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     22\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33mcoedge_features\u001b[39m\u001b[33m\"\u001b[39m] = standardize_features(data[\u001b[33m\"\u001b[39m\u001b[33mcoedge_features\u001b[39m\u001b[33m\"\u001b[39m], feature_standardization[\u001b[33m\"\u001b[39m\u001b[33mcoedge_features\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\workspace\\projects\\freelance\\BRepMocAutoencoder\\src\\dataset.py:12\u001b[39m, in \u001b[36mstandardize_features\u001b[39m\u001b[34m(feature_tensor, stats)\u001b[39m\n\u001b[32m     10\u001b[39m sds = np.array([s[\u001b[33m\"\u001b[39m\u001b[33mstandard_deviation\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m stats])\n\u001b[32m     11\u001b[39m eps = \u001b[32m1e-7\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m np.all(sds > eps), \u001b[33m\"\u001b[39m\u001b[33mFeature has zero standard deviation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m means_x = np.expand_dims(means, axis=\u001b[32m0\u001b[39m)\n\u001b[32m     14\u001b[39m sds_x = np.expand_dims(sds, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mAssertionError\u001b[39m: Feature has zero standard deviation"
     ]
    }
   ],
   "source": [
    "from src.dataset import BrepNetDataset\n",
    "import torch\n",
    "STATS_BREPNET = PROCESSED_DATA_DIR / \"dataset_stats.json\"\n",
    "\n",
    "BREP_NPZ_DIR = PROCESSED_DATA_DIR / \"features\" / \"brep\"\n",
    "\n",
    "train_dataset = BrepNetDataset(STATS_BREPNET, BREP_NPZ_DIR, split=\"training_set\")\n",
    "val_dataset = BrepNetDataset(STATS_BREPNET, BREP_NPZ_DIR, split=\"validation_set\")\n",
    "test_dataset = BrepNetDataset(STATS_BREPNET, BREP_NPZ_DIR, split=\"test_set\")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")\n",
    "for k, v in train_dataset[0].items():\n",
    "    print(f\"{k}: {tuple(v.shape) if isinstance(v, torch.Tensor) else type(v)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brepnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
