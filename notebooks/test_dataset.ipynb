{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ad9cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path: d:\\google_drive\\–ú–æ–π –¥–∏—Å–∫\\projects\\BRepMocAutoencoder\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import notebook_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1b821",
   "metadata": {},
   "source": [
    "–ø—Ä–æ–≤–µ—Ä–∏–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900139f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-06 01:11:01.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: D:\\google_drive\\–ú–æ–π –¥–∏—Å–∫\\projects\\BRepMocAutoencoder\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: 132\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –†–ê–ó–ú–ï–†–ù–û–°–¢–Ø–ú –ü–†–ò–ó–ù–ê–ö–û–í:\n",
      "================================================================================\n",
      "\n",
      "üìä Edge Features:\n",
      "   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 10: 132 —Ñ–∞–π–ª–æ–≤\n",
      "\n",
      "üìä Face Features:\n",
      "   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 7: 132 —Ñ–∞–π–ª–æ–≤\n",
      "\n",
      "üìä Coedge Features:\n",
      "   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 1: 132 —Ñ–∞–π–ª–æ–≤\n",
      "\n",
      "================================================================================\n",
      "‚úÖ –í–°–ï –§–ê–ô–õ–´ –ò–ú–ï–Æ–¢ –û–î–ò–ù–ê–ö–û–í–´–ï –†–ê–ó–ú–ï–†–ù–û–°–¢–ò –ü–†–ò–ó–ù–ê–ö–û–í!\n",
      "   Edge features: 10\n",
      "   Face features: 7\n",
      "   Coedge features: 1\n"
     ]
    }
   ],
   "source": [
    "from src.config import PROCESSED_DATA_DIR\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "BREP_NPZ_DIR = PROCESSED_DATA_DIR / \"features\" / \"brep\"\n",
    "npz_files = list(BREP_NPZ_DIR.glob(\"*.npz\"))\n",
    "\n",
    "print(f\"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(npz_files)}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "edge_dims = defaultdict(list)\n",
    "face_dims = defaultdict(list)\n",
    "coedge_dims = defaultdict(list)\n",
    "\n",
    "for i, npz_path in enumerate(npz_files):\n",
    "    with np.load(npz_path) as data:\n",
    "        edge_shape = data['edge_features'].shape\n",
    "        face_shape = data['face_features'].shape\n",
    "        coedge_shape = data['coedge_features'].shape\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤—Ç–æ—Ä–æ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ)\n",
    "        edge_dims[edge_shape[1]].append(npz_path.name)\n",
    "        face_dims[face_shape[1]].append(npz_path.name)\n",
    "        coedge_dims[coedge_shape[1]].append(npz_path.name)\n",
    "\n",
    "        # –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã —Å –Ω–µ–æ–±—ã—á–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è–º–∏\n",
    "        if edge_shape[1] != 10 or face_shape[1] != 7 or coedge_shape[1] != 1:\n",
    "            print(f\"‚ö†Ô∏è  {npz_path.name}\")\n",
    "            print(f\"   edges: {edge_shape}, faces: {face_shape}, coedges: {coedge_shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –†–ê–ó–ú–ï–†–ù–û–°–¢–Ø–ú –ü–†–ò–ó–ù–ê–ö–û–í:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Edge Features:\")\n",
    "for dim, files in sorted(edge_dims.items()):\n",
    "    print(f\"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {dim}: {len(files)} —Ñ–∞–π–ª–æ–≤\")\n",
    "    if len(files) <= 5:\n",
    "        for f in files:\n",
    "            print(f\"      - {f}\")\n",
    "\n",
    "print(\"\\nüìä Face Features:\")\n",
    "for dim, files in sorted(face_dims.items()):\n",
    "    print(f\"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {dim}: {len(files)} —Ñ–∞–π–ª–æ–≤\")\n",
    "    if len(files) <= 5:\n",
    "        for f in files:\n",
    "            print(f\"      - {f}\")\n",
    "\n",
    "print(\"\\nüìä Coedge Features:\")\n",
    "for dim, files in sorted(coedge_dims.items()):\n",
    "    print(f\"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {dim}: {len(files)} —Ñ–∞–π–ª–æ–≤\")\n",
    "    if len(files) <= 5:\n",
    "        for f in files:\n",
    "            print(f\"      - {f}\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if len(edge_dims) > 1 or len(face_dims) > 1 or len(coedge_dims) > 1:\n",
    "    print(\"‚ùå –ü–†–û–ë–õ–ï–ú–ê: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ñ–∞–π–ª—ã —Å –†–ê–ó–ù–´–ú–ò —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!\")\n",
    "    print(\"   –≠—Ç–æ –ø—Ä–∏–≤–µ–¥—ë—Ç –∫ –æ—à–∏–±–∫–∞–º –ø—Ä–∏ –±–∞—Ç—á–∏–Ω–≥–µ –≤ PyTorch Geometric.\")\n",
    "    print(\"\\n   –†–µ—à–µ–Ω–∏–µ: –ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –µ–¥–∏–Ω–æ–π feature_schema.\")\n",
    "else:\n",
    "    print(\"‚úÖ –í–°–ï –§–ê–ô–õ–´ –ò–ú–ï–Æ–¢ –û–î–ò–ù–ê–ö–û–í–´–ï –†–ê–ó–ú–ï–†–ù–û–°–¢–ò –ü–†–ò–ó–ù–ê–ö–û–í!\")\n",
    "    print(f\"   Edge features: {list(edge_dims.keys())[0]}\")\n",
    "    print(f\"   Face features: {list(face_dims.keys())[0]}\")\n",
    "    print(f\"   Coedge features: {list(coedge_dims.keys())[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d818984d",
   "metadata": {},
   "source": [
    "—Å–æ–∑–¥–∞–¥–∏–º –¥–∞—Ç–∞—Å–µ—Ç –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–º –¥–∞–Ω–Ω—ã–µ –≤ —Ç–µ–Ω–∑–æ—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05b807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def standardize_features(feature_tensor, stats):\n",
    "\n",
    "    means = np.array([s[\"mean\"] for s in stats])\n",
    "    sds = np.array([s[\"standard_deviation\"] for s in stats])\n",
    "    eps = 1e-7\n",
    "    assert np.all(sds > eps), \"Feature has zero standard deviation\"\n",
    "    means_x = np.expand_dims(means, axis=0)\n",
    "    sds_x = np.expand_dims(sds, axis=0)\n",
    "    feature_tensor_zero_mean = feature_tensor - means_x\n",
    "    feature_tensor_standardized = feature_tensor_zero_mean / sds_x\n",
    "    return feature_tensor_standardized.astype(np.float32)\n",
    "\n",
    "def standarize_data(data, feature_standardization):\n",
    "    data[\"face_features\"] = standardize_features(data[\"face_features\"], feature_standardization[\"face_features\"])\n",
    "    data[\"edge_features\"] = standardize_features(data[\"edge_features\"], feature_standardization[\"edge_features\"])\n",
    "    data[\"coedge_features\"] = standardize_features(data[\"coedge_features\"], feature_standardization[\"coedge_features\"])\n",
    "    return data\n",
    "\n",
    "\n",
    "class BrepNetDataset(Dataset):\n",
    "    def __init__(self, json_path, feats_brep_dir, split=\"training_set\"):\n",
    "        with open(json_path, encoding=\"utf-8\") as f:\n",
    "            stats = json.load(f)\n",
    "        self.files = stats[split]\n",
    "        self.feature_standardization = stats[\"feature_standardization\"]\n",
    "        self.split = split\n",
    "        self.brep_dir = feats_brep_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        brep_path = os.path.join(self.brep_dir, file_name + \".npz\")\n",
    "\n",
    "        D = np.load(brep_path, allow_pickle=True)\n",
    "\n",
    "        data_np = {\n",
    "            \"vertex\": D[\"vertex\"].astype(np.float32),\n",
    "            \"edge_features\": D[\"edge_features\"].astype(np.float32),\n",
    "            \"face_features\": D[\"face_features\"].astype(np.float32),\n",
    "            \"coedge_features\": D[\"coedge_features\"].astype(np.float32),\n",
    "        }\n",
    "\n",
    "        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "        if self.split == \"training_set\" and self.feature_standardization is not None:\n",
    "             # standarize_data –æ–∂–∏–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –∫–ª—é—á–∞–º–∏\n",
    "\n",
    "             data_to_standardize = {\n",
    "                 \"face_features\": data_np[\"face_features\"],\n",
    "                 \"edge_features\": data_np[\"edge_features\"],\n",
    "                 \"coedge_features\": data_np[\"coedge_features\"]\n",
    "             }\n",
    "             standardized_data = standarize_data(data_to_standardize, self.feature_standardization)\n",
    "             # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ data_np\n",
    "             data_np.update(standardized_data)\n",
    "\n",
    "        return {\n",
    "            \"name\": file_name,\n",
    "            \"vertices\": torch.from_numpy(data_np[\"vertex\"]),\n",
    "            \"edges\": torch.from_numpy(data_np[\"edge_features\"]),\n",
    "            \"faces\": torch.from_numpy(data_np[\"face_features\"]),\n",
    "            \"edge_to_vertex\": torch.from_numpy(D[\"edge_to_vertex\"].astype(np.int64)),\n",
    "            \"face_to_edge\": torch.from_numpy(D[\"face_to_edge\"].astype(np.int64)),\n",
    "            \"face_to_face\": torch.from_numpy(D[\"face_to_face\"].astype(np.int64)),\n",
    "            \"sdf_uv\": torch.from_numpy(D[\"uv_faces\"].astype(np.float32)),\n",
    "            \"sdf_vals\": torch.from_numpy(D[\"sdf_faces\"].astype(np.float32))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d70f6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 94, Val samples: 24, Test samples: 14\n",
      "name: <class 'str'>\n",
      "vertices: (339, 3)\n",
      "edges: (521, 10)\n",
      "faces: (176, 7)\n",
      "edge_to_vertex: (2, 521)\n",
      "face_to_edge: (2, 1029)\n",
      "face_to_face: (2, 495)\n",
      "sdf_uv: (176, 500, 2)\n",
      "sdf_vals: (176, 500)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.config import PROCESSED_DATA_DIR\n",
    "STATS_BREPNET = PROCESSED_DATA_DIR / \"dataset_stats.json\"\n",
    "\n",
    "BREP_NPZ_DIR = PROCESSED_DATA_DIR / \"features\" / \"brep\"\n",
    "\n",
    "train_dataset = BrepNetDataset(STATS_BREPNET, BREP_NPZ_DIR, split=\"training_set\")\n",
    "val_dataset = BrepNetDataset(STATS_BREPNET, BREP_NPZ_DIR, split=\"validation_set\")\n",
    "test_dataset = BrepNetDataset(STATS_BREPNET, BREP_NPZ_DIR, split=\"test_set\")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")\n",
    "sample_dataset = train_dataset[3]\n",
    "for k, v in sample_dataset.items():\n",
    "    print(f\"{k}: {tuple(v.shape) if isinstance(v, torch.Tensor) else type(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd48a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def augment_brep_data(data, \n",
    "                      feature_noise_std=0.05,\n",
    "                      feature_dropout_prob=0.1,\n",
    "                      feature_scale_range=(0.9, 1.1)):\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –°–¢–û–•–ê–°–¢–ò–ß–ï–°–ö–ò–ï –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º BRep.\n",
    "    \n",
    "    –í–ê–ñ–ù–û: –ö–∞–∂–¥—ã–π –≤—ã–∑–æ–≤ —Å–æ–∑–¥–∞—ë—Ç –†–ê–ó–ù–´–ï —Å–ª—É—á–∞–π–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è!\n",
    "    \"\"\"\n",
    "    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å –∏ –∫–ª–æ–Ω–∏—Ä—É–µ–º —Ç–µ–Ω–∑–æ—Ä—ã\n",
    "    augmented_data = {}\n",
    "    for k, v in data.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            augmented_data[k] = v.clone()\n",
    "        else:\n",
    "            augmented_data[k] = v\n",
    "\n",
    "    # 1. –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤–µ—Ä—à–∏–Ω (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è)\n",
    "    if 'vertices' in augmented_data:\n",
    "        vertices = augmented_data['vertices']\n",
    "        if feature_noise_std > 0:\n",
    "            # –ù–µ–±–æ–ª—å—à–æ–π jitter –¥–ª—è –≤–µ—Ä—à–∏–Ω\n",
    "            jitter = torch.randn_like(vertices) * feature_noise_std * 0.05\n",
    "            vertices = vertices + jitter\n",
    "            augmented_data['vertices'] = vertices\n",
    "\n",
    "    # 2. –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä—ë–±–µ—Ä\n",
    "    if 'edges' in augmented_data:\n",
    "        edges = augmented_data['edges']\n",
    "        \n",
    "        # 2.1 Gaussian noise\n",
    "        if feature_noise_std > 0:\n",
    "            edge_noise = torch.randn_like(edges) * feature_noise_std\n",
    "            edges = edges + edge_noise\n",
    "        \n",
    "        # 2.2 Feature dropout (–∑–∞–Ω—É–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)\n",
    "        if feature_dropout_prob > 0:\n",
    "            edge_mask = (torch.rand_like(edges) > feature_dropout_prob).float()\n",
    "            edges = edges * edge_mask\n",
    "        \n",
    "        # 2.3 –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        if feature_scale_range is not None:\n",
    "            scale = np.random.uniform(feature_scale_range[0], feature_scale_range[1])\n",
    "            edges = edges * scale\n",
    "        \n",
    "        # –í–∞–∂–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ä—ë–±—Ä–∞\n",
    "        augmented_data['edges'] = edges\n",
    "\n",
    "    # 3. –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≥—Ä–∞–Ω–µ–π\n",
    "    if 'faces' in augmented_data:\n",
    "        faces = augmented_data['faces']\n",
    "        \n",
    "        # 3.1 Gaussian noise\n",
    "        if feature_noise_std > 0:\n",
    "            face_noise = torch.randn_like(faces) * feature_noise_std\n",
    "            faces = faces + face_noise\n",
    "        \n",
    "        # 3.2 Feature dropout\n",
    "        if feature_dropout_prob > 0:\n",
    "            face_mask = (torch.rand_like(faces) > feature_dropout_prob).float()\n",
    "            faces = faces * face_mask\n",
    "        \n",
    "        # 3.3 –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        if feature_scale_range is not None:\n",
    "            scale = np.random.uniform(feature_scale_range[0], feature_scale_range[1])\n",
    "            faces = faces * scale\n",
    "        \n",
    "        # –í–∞–∂–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏\n",
    "        augmented_data['faces'] = faces\n",
    "\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10ee42a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–ô\n",
      "================================================================================\n",
      "\n",
      "üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n",
      "   vertices: torch.Size([297, 3]), mean=0.0884\n",
      "   edges: torch.Size([459, 10]), mean=-0.0217\n",
      "   faces: torch.Size([157, 7]), mean=-0.0209\n",
      "\n",
      "üìä –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è 1:\n",
      "   vertices: mean=0.0884\n",
      "   edges: mean=-0.0182\n",
      "   faces: mean=-0.0174\n",
      "\n",
      "üìä –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è 2:\n",
      "   vertices: mean=0.0883\n",
      "   edges: mean=-0.0213\n",
      "   faces: mean=-0.0276\n",
      "\n",
      "================================================================================\n",
      "üîç –†–ê–ó–ù–ò–¶–ê –ú–ï–ñ–î–£ –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–Ø–ú–ò:\n",
      "================================================================================\n",
      "   vertex_diff: 0.002787\n",
      "   edge_diff:   0.165584\n",
      "   face_diff:   0.151854\n",
      "\n",
      "================================================================================\n",
      "‚úÖ –û–¶–ï–ù–ö–ê:\n",
      "================================================================================\n",
      "‚úÖ vertex_diff OK (0.002787)\n",
      "‚úÖ edge_diff OK (0.165584)\n",
      "‚úÖ face_diff OK (0.151854)\n",
      "\n",
      "================================================================================\n",
      "üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:\n",
      "================================================================================\n",
      "–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:\n",
      "   vertex_diff: 0.002 - 0.01\n",
      "   edge_diff:   0.05 - 0.20\n",
      "   face_diff:   0.05 - 0.20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–ô\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# –ë–µ—Ä—ë–º –æ–¥–∏–Ω –æ–±—Ä–∞–∑–µ—Ü\n",
    "sample = train_dataset[0]\n",
    "\n",
    "print(f\"\\nüìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\")\n",
    "print(f\"   vertices: {sample['vertices'].shape}, mean={sample['vertices'].mean():.4f}\")\n",
    "print(f\"   edges: {sample['edges'].shape}, mean={sample['edges'].mean():.4f}\")\n",
    "print(f\"   faces: {sample['faces'].shape}, mean={sample['faces'].mean():.4f}\")\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –¥–≤–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "aug1 = augment_brep_data(sample)\n",
    "aug2 = augment_brep_data(sample)\n",
    "\n",
    "print(f\"\\nüìä –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è 1:\")\n",
    "print(f\"   vertices: mean={aug1['vertices'].mean():.4f}\")\n",
    "print(f\"   edges: mean={aug1['edges'].mean():.4f}\")\n",
    "print(f\"   faces: mean={aug1['faces'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nüìä –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è 2:\")\n",
    "print(f\"   vertices: mean={aug2['vertices'].mean():.4f}\")\n",
    "print(f\"   edges: mean={aug2['edges'].mean():.4f}\")\n",
    "print(f\"   faces: mean={aug2['faces'].mean():.4f}\")\n",
    "\n",
    "# –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏\n",
    "vertex_diff = (aug1['vertices'] - aug2['vertices']).abs().mean().item()\n",
    "edge_diff = (aug1['edges'] - aug2['edges']).abs().mean().item()\n",
    "face_diff = (aug1['faces'] - aug2['faces']).abs().mean().item()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîç –†–ê–ó–ù–ò–¶–ê –ú–ï–ñ–î–£ –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–Ø–ú–ò:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"   vertex_diff: {vertex_diff:.6f}\")\n",
    "print(f\"   edge_diff:   {edge_diff:.6f}\")\n",
    "print(f\"   face_diff:   {face_diff:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ –û–¶–ï–ù–ö–ê:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞\n",
    "if vertex_diff < 0.001:\n",
    "    print(\"‚ùå vertex_diff –°–õ–ò–®–ö–û–ú –ú–ê–õ–ï–ù–¨–ö–ò–ô! –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤–µ—Ä—à–∏–Ω –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç.\")\n",
    "else:\n",
    "    print(f\"‚úÖ vertex_diff OK ({vertex_diff:.6f})\")\n",
    "\n",
    "if edge_diff < 0.01:\n",
    "    print(\"‚ùå edge_diff –°–õ–ò–®–ö–û–ú –ú–ê–õ–ï–ù–¨–ö–ò–ô! –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ä—ë–±–µ—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç.\")\n",
    "elif edge_diff > 0.5:\n",
    "    print(f\"‚ö†Ô∏è  edge_diff –°–õ–ò–®–ö–û–ú –ë–û–õ–¨–®–û–ô! –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–ª–∏—à–∫–æ–º —Å–∏–ª—å–Ω—ã–µ ({edge_diff:.6f})\")\n",
    "else:\n",
    "    print(f\"‚úÖ edge_diff OK ({edge_diff:.6f})\")\n",
    "\n",
    "if face_diff < 0.01:\n",
    "    print(\"‚ùå face_diff –°–õ–ò–®–ö–û–ú –ú–ê–õ–ï–ù–¨–ö–ò–ô! –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≥—Ä–∞–Ω–µ–π –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç.\")\n",
    "elif face_diff > 0.5:\n",
    "    print(f\"‚ö†Ô∏è  face_diff –°–õ–ò–®–ö–û–ú –ë–û–õ–¨–®–û–ô! –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–ª–∏—à–∫–æ–º —Å–∏–ª—å–Ω—ã–µ ({face_diff:.6f})\")\n",
    "else:\n",
    "    print(f\"‚úÖ face_diff OK ({face_diff:.6f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:\")\n",
    "print(\"   vertex_diff: 0.002 - 0.01\")\n",
    "print(\"   edge_diff:   0.05 - 0.20\")\n",
    "print(\"   face_diff:   0.05 - 0.20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b33746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ –¢–ï–°–¢: –°—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π (10 –ø—Ä–æ–≥–æ–Ω–æ–≤)\n",
      "================================================================================\n",
      "–ü—Ä–æ–≥–æ–Ω  1: vertex=0.002777, edge=0.170074, face=0.128848\n",
      "–ü—Ä–æ–≥–æ–Ω  2: vertex=0.002824, edge=0.218943, face=0.136959\n",
      "–ü—Ä–æ–≥–æ–Ω  3: vertex=0.002825, edge=0.194156, face=0.133064\n",
      "–ü—Ä–æ–≥–æ–Ω  4: vertex=0.002746, edge=0.164634, face=0.136113\n",
      "–ü—Ä–æ–≥–æ–Ω  5: vertex=0.002777, edge=0.185291, face=0.126717\n",
      "–ü—Ä–æ–≥–æ–Ω  6: vertex=0.002878, edge=0.178229, face=0.122451\n",
      "–ü—Ä–æ–≥–æ–Ω  7: vertex=0.002854, edge=0.179669, face=0.150313\n",
      "–ü—Ä–æ–≥–æ–Ω  8: vertex=0.002897, edge=0.168956, face=0.129059\n",
      "–ü—Ä–æ–≥–æ–Ω  9: vertex=0.002830, edge=0.181359, face=0.170781\n",
      "–ü—Ä–æ–≥–æ–Ω 10: vertex=0.002937, edge=0.165610, face=0.125414\n",
      "\n",
      "================================================================================\n",
      "üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê (10 –ø—Ä–æ–≥–æ–Ω–æ–≤):\n",
      "================================================================================\n",
      "vertex_diff: mean=0.002835, std=0.000059\n",
      "edge_diff:   mean=0.180692, std=0.016360\n",
      "face_diff:   mean=0.135972, std=0.014550\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"üß™ –¢–ï–°–¢: –°—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π (10 –ø—Ä–æ–≥–æ–Ω–æ–≤)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "sample = train_dataset[0]\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º 10 –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π\n",
    "vertex_diffs = []\n",
    "edge_diffs = []\n",
    "face_diffs = []\n",
    "\n",
    "for i in range(10):\n",
    "    aug1 = augment_brep_data(sample)\n",
    "    aug2 = augment_brep_data(sample)\n",
    "    \n",
    "    vertex_diff = (aug1['vertices'] - aug2['vertices']).abs().mean().item()\n",
    "    edge_diff = (aug1['edges'] - aug2['edges']).abs().mean().item()\n",
    "    face_diff = (aug1['faces'] - aug2['faces']).abs().mean().item()\n",
    "    \n",
    "    vertex_diffs.append(vertex_diff)\n",
    "    edge_diffs.append(edge_diff)\n",
    "    face_diffs.append(face_diff)\n",
    "    \n",
    "    print(f\"–ü—Ä–æ–≥–æ–Ω {i+1:2d}: vertex={vertex_diff:.6f}, edge={edge_diff:.6f}, face={face_diff:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê (10 –ø—Ä–æ–≥–æ–Ω–æ–≤):\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"vertex_diff: mean={sum(vertex_diffs)/10:.6f}, std={torch.tensor(vertex_diffs).std():.6f}\")\n",
    "print(f\"edge_diff:   mean={sum(edge_diffs)/10:.6f}, std={torch.tensor(edge_diffs).std():.6f}\")\n",
    "print(f\"face_diff:   mean={sum(face_diffs)/10:.6f}, std={torch.tensor(face_diffs).std():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d601cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def moco_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –∫–æ–ª–ª–∞—Ü–∏–∏ –¥–ª—è DataLoader MoCo.\n",
    "    \"\"\"\n",
    "    data_list_q = []\n",
    "    data_list_k = []\n",
    "\n",
    "    for idx, data_item in enumerate(batch):\n",
    "        augmented_q = augment_brep_data(data_item)\n",
    "        augmented_k = augment_brep_data(data_item)\n",
    "\n",
    "        data_q = Data(\n",
    "            x=augmented_q['vertices'],\n",
    "            edge_attr=augmented_q['edges'],\n",
    "            face_attr=augmented_q['faces'],\n",
    "            edge_index=augmented_q['edge_to_vertex'],\n",
    "        )\n",
    "\n",
    "        data_k = Data(\n",
    "            x=augmented_k['vertices'],\n",
    "            edge_attr=augmented_k['edges'],\n",
    "            face_attr=augmented_k['faces'],\n",
    "            edge_index=augmented_k['edge_to_vertex'],\n",
    "        )\n",
    "\n",
    "        data_list_q.append(data_q)\n",
    "        data_list_k.append(data_k)\n",
    "\n",
    "    # –ë–∞—Ç—á–∏–º —Ç–æ–ª—å–∫–æ —Å follow_batch –¥–ª—è face_attr\n",
    "    batch_q = Batch.from_data_list(data_list_q, follow_batch=['face_attr'])\n",
    "    batch_k = Batch.from_data_list(data_list_k, follow_batch=['face_attr'])\n",
    "\n",
    "    # –í—Ä—É—á–Ω—É—é —Å–æ–∑–¥–∞–µ–º edges_batch\n",
    "    for batch_obj, data_list in [(batch_q, data_list_q), (batch_k, data_list_k)]:\n",
    "        _add_edges_batch(batch_obj, data_list)\n",
    "        _rename_and_add_lists(batch_obj, batch)\n",
    "\n",
    "    return batch_q, batch_k\n",
    "\n",
    "\n",
    "def simple_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–ª–ª–∞—Ü–∏–∏ –±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π.\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "\n",
    "    for data_item in batch:\n",
    "        data_obj = Data(\n",
    "            x=data_item['vertices'],\n",
    "            edge_attr=data_item['edges'],\n",
    "            face_attr=data_item['faces'],\n",
    "            edge_index=data_item['edge_to_vertex'],\n",
    "        )\n",
    "        data_list.append(data_obj)\n",
    "\n",
    "    batch_data = Batch.from_data_list(data_list, follow_batch=['face_attr'])\n",
    "    \n",
    "    # –í—Ä—É—á–Ω—É—é —Å–æ–∑–¥–∞–µ–º edges_batch\n",
    "    _add_edges_batch(batch_data, data_list)\n",
    "    _rename_and_add_lists(batch_data, batch)\n",
    "\n",
    "    return batch_data\n",
    "\n",
    "\n",
    "def _add_edges_batch(batch_obj, data_list):\n",
    "    \"\"\"–°–æ–∑–¥–∞–µ—Ç edges_batch –≤—Ä—É—á–Ω—É—é.\"\"\"\n",
    "    edges_batch_list = []\n",
    "    for graph_idx, data in enumerate(data_list):\n",
    "        num_edges = data.edge_attr.size(0)\n",
    "        edges_batch_list.append(torch.full((num_edges,), graph_idx, dtype=torch.long))\n",
    "    \n",
    "    batch_obj.edges_batch = torch.cat(edges_batch_list)\n",
    "\n",
    "\n",
    "def _rename_and_add_lists(batch_obj, original_batch):\n",
    "    \"\"\"–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç –∞—Ç—Ä–∏–±—É—Ç—ã –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç —Å–ø–∏—Å–∫–∏.\"\"\"\n",
    "    batch_obj.vertices = batch_obj.x\n",
    "    batch_obj.edges = batch_obj.edge_attr\n",
    "    batch_obj.faces = batch_obj.face_attr\n",
    "    batch_obj.edge_to_vertex = batch_obj.edge_index\n",
    "    batch_obj.faces_batch = batch_obj.face_attr_batch\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–∏—Å–∫–∏ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –±–∞—Ç—á–∞\n",
    "    batch_obj.sdf_uv_list = [d['sdf_uv'] for d in original_batch]\n",
    "    batch_obj.sdf_vals_list = [d['sdf_vals'] for d in original_batch]\n",
    "    batch_obj.face_to_edge_list = [d['face_to_edge'] for d in original_batch]\n",
    "    batch_obj.face_to_face_list = [d['face_to_face'] for d in original_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7619d159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ –¢–ï–°–¢: –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –±–∞—Ç—á–µ (moco_collate_fn)\n",
      "================================================================================\n",
      "\n",
      "üì¶ –ë–∞—Ç—á —Å–æ–∑–¥–∞–Ω:\n",
      "   batch_q.num_graphs: 4\n",
      "   batch_k.num_graphs: 4\n",
      "\n",
      "üîç –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É query –∏ key –±–∞—Ç—á–∞–º–∏:\n",
      "   vertex_diff: 0.002791\n",
      "   edge_diff:   0.192943\n",
      "   face_diff:   0.138578\n",
      "\n",
      "================================================================================\n",
      "‚úÖ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –±–∞—Ç—á–µ —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!\n",
      "   edge_diff_batch (0.192943) –≤ –Ω–æ—Ä–º–µ\n",
      "   face_diff_batch (0.138578) –≤ –Ω–æ—Ä–º–µ\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ –¢–ï–°–¢: –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –±–∞—Ç—á–µ (moco_collate_fn)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –º–∞–ª–µ–Ω—å–∫–∏–π –±–∞—Ç—á\n",
    "test_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=moco_collate_fn,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "batch_q, batch_k = next(iter(test_loader))\n",
    "\n",
    "print(f\"\\nüì¶ –ë–∞—Ç—á —Å–æ–∑–¥–∞–Ω:\")\n",
    "print(f\"   batch_q.num_graphs: {batch_q.num_graphs}\")\n",
    "print(f\"   batch_k.num_graphs: {batch_k.num_graphs}\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É query –∏ key\n",
    "vertex_diff_batch = (batch_q.vertices - batch_k.vertices).abs().mean().item()\n",
    "edge_diff_batch = (batch_q.edges - batch_k.edges).abs().mean().item()\n",
    "face_diff_batch = (batch_q.faces - batch_k.faces).abs().mean().item()\n",
    "\n",
    "print(f\"\\nüîç –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É query –∏ key –±–∞—Ç—á–∞–º–∏:\")\n",
    "print(f\"   vertex_diff: {vertex_diff_batch:.6f}\")\n",
    "print(f\"   edge_diff:   {edge_diff_batch:.6f}\")\n",
    "print(f\"   face_diff:   {face_diff_batch:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if edge_diff_batch < 0.01 or face_diff_batch < 0.01:\n",
    "    print(\"‚ùå –ü–†–û–ë–õ–ï–ú–ê: –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –±–∞—Ç—á–µ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç!\")\n",
    "    print(\"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ moco_collate_fn - –≤–æ–∑–º–æ–∂–Ω–æ, –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è.\")\n",
    "else:\n",
    "    print(\"‚úÖ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –±–∞—Ç—á–µ —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!\")\n",
    "    print(f\"   edge_diff_batch ({edge_diff_batch:.6f}) –≤ –Ω–æ—Ä–º–µ\")\n",
    "    print(f\"   face_diff_batch ({face_diff_batch:.6f}) –≤ –Ω–æ—Ä–º–µ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5d6b6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–∞—Ç—á–µ –≥—Ä–∞—Ñ–æ–≤ (–∑–∞–ø—Ä–æ—Å):\n",
      "–¢–∏–ø –æ–±—ä–µ–∫—Ç–∞: <class 'abc.DataBatch'>\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –≥—Ä–∞—Ñ–æ–≤ –≤ –±–∞—Ç—á–µ: 32\n",
      "–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Ä—à–∏–Ω –≤ –±–∞—Ç—á–µ: 3063\n",
      "–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ –≤–µ—Ä—à–∏–Ω: torch.Size([3063, 3])\n",
      "–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–±–µ—Ä (–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–µ–±–µ—Ä) –≤ –±–∞—Ç—á–µ: 4751\n",
      "–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–µ–±–µ—Ä: torch.Size([4751, 10])\n",
      "–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä–∞–Ω–µ–π (–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≥—Ä–∞–Ω–µ–π) –≤ –±–∞—Ç—á–µ: 1740\n",
      "–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≥—Ä–∞–Ω–µ–π: torch.Size([1740, 7])\n",
      "–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π 'edge_to_vertex' –≤ –±–∞—Ç—á–µ: 4751\n",
      "–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ 'edge_to_vertex': torch.Size([2, 4751])\n",
      "–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π 'face_to_edge' –≤ –±–∞—Ç—á–µ: 32\n",
      "–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ 'face_to_edge': torch.Size([2, 198])\n",
      "–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π 'face_to_face' –≤ –±–∞—Ç—á–µ: 32\n",
      "–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ 'face_to_face': torch.Size([2, 96])\n",
      "–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ sdf_uv –≤ –±–∞—Ç—á–µ: 32\n",
      "–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ sdf_uv: torch.Size([38, 500, 2])\n",
      "–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ sdf_vals –≤ –±–∞—Ç—á–µ: 32\n",
      "–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ sdf_vals: torch.Size([38, 500])\n",
      "–§–æ—Ä–º–∞ –∞—Ç—Ä–∏–±—É—Ç–∞ 'batch' (–¥–ª—è –≤–µ—Ä—à–∏–Ω): torch.Size([3063])\n",
      "–ü—Ä–∏–º–µ—Ä –∞—Ç—Ä–∏–±—É—Ç–∞ 'batch' (–ø–µ—Ä–≤—ã–µ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤): tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sample_batch_q, sample_batch_k = next(iter(test_train_loader))\n",
    "\n",
    "    print(\"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–∞—Ç—á–µ –≥—Ä–∞—Ñ–æ–≤ (–∑–∞–ø—Ä–æ—Å):\")\n",
    "    \n",
    "    print(f\"–¢–∏–ø –æ–±—ä–µ–∫—Ç–∞: {type(sample_batch_q)}\")\n",
    "    print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –≥—Ä–∞—Ñ–æ–≤ –≤ –±–∞—Ç—á–µ: {sample_batch_q.num_graphs}\")\n",
    "    \n",
    "    print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Ä—à–∏–Ω –≤ –±–∞—Ç—á–µ: {sample_batch_q.vertices.size(0)}\")\n",
    "    print(f\"–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ –≤–µ—Ä—à–∏–Ω: {sample_batch_q.vertices.shape}\")\n",
    "    \n",
    "    print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–±–µ—Ä (–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–µ–±–µ—Ä) –≤ –±–∞—Ç—á–µ: {sample_batch_q.edges.size(0)}\")\n",
    "    print(f\"–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–µ–±–µ—Ä: {sample_batch_q.edges.shape}\")\n",
    "\n",
    "    print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä–∞–Ω–µ–π (–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≥—Ä–∞–Ω–µ–π) –≤ –±–∞—Ç—á–µ: {sample_batch_q.faces.size(0)}\")\n",
    "    print(f\"–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≥—Ä–∞–Ω–µ–π: {sample_batch_q.faces.shape}\")\n",
    "\n",
    "    print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π 'edge_to_vertex' –≤ –±–∞—Ç—á–µ: {sample_batch_q.edge_to_vertex.size(1)}\")\n",
    "    print(f\"–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ 'edge_to_vertex': {sample_batch_q.edge_to_vertex.shape}\")\n",
    "\n",
    "    print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π 'face_to_edge' –≤ –±–∞—Ç—á–µ: {len(sample_batch_q.face_to_edge_list)}\")\n",
    "    print(f\"–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ 'face_to_edge': {sample_batch_q.face_to_edge_list[0].shape}\")\n",
    "\n",
    "    print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π 'face_to_face' –≤ –±–∞—Ç—á–µ: {len(sample_batch_q.face_to_face_list)}\")\n",
    "    print(f\"–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ 'face_to_face': {sample_batch_q.face_to_face_list[0].shape}\")\n",
    "\n",
    "    print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ sdf_uv –≤ –±–∞—Ç—á–µ: {len(sample_batch_q.sdf_uv_list)}\")\n",
    "    print(f\"–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ sdf_uv: {sample_batch_q.sdf_uv_list[0].shape}\")\n",
    "\n",
    "    print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ sdf_vals –≤ –±–∞—Ç—á–µ: {len(sample_batch_q.sdf_vals_list)}\")\n",
    "    print(f\"–§–æ—Ä–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ sdf_vals: {sample_batch_q.sdf_vals_list[0].shape}\")\n",
    "\n",
    "    print(f\"–§–æ—Ä–º–∞ –∞—Ç—Ä–∏–±—É—Ç–∞ 'batch' (–¥–ª—è –≤–µ—Ä—à–∏–Ω): {sample_batch_q.batch.shape}\")\n",
    "    print(f\"–ü—Ä–∏–º–µ—Ä –∞—Ç—Ä–∏–±—É—Ç–∞ 'batch' (–ø–µ—Ä–≤—ã–µ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤): {sample_batch_q.batch[:10]}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–∏–º–µ—Ä–∞ –±–∞—Ç—á–∞: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brepnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
